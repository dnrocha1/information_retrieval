{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm5Xy8tqr3EG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqFF1HcsTIw"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/dnrocha1/information_retrieval/master/lab02/data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3G0Wz9jJsdP6"
   },
   "outputs": [],
   "source": [
    "#pre-process\n",
    "\n",
    "documents = data['text'].apply(lambda x: x.lower())\n",
    "\n",
    "regex = RegexpTokenizer(r'\\b[A-zÀ-ú-\\'\\d]{3,}')\n",
    "# tokens = regex.tokenize(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hp01Qfl6ummO"
   },
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "\n",
    "def build_index(documents=documents):\n",
    "  inverted_list = {}\n",
    "\n",
    "  n_doc = 0\n",
    "  for document in documents:\n",
    "    n_doc += 1\n",
    "    doc_list.append(n_doc)\n",
    "    token = regex.tokenize(document)\n",
    "    counter = list(Counter(token).items())\n",
    "    for elem in counter:\n",
    "      key = elem[0]\n",
    "      freq = elem[1]\n",
    "      if key in inverted_list.keys():\n",
    "        if n_doc not in inverted_list[key][0]:\n",
    "          inverted_list[key].append((n_doc,freq))\n",
    "      else:\n",
    "        inverted_list[key] = [(n_doc,freq)]\n",
    "  \n",
    "  return inverted_list\n",
    "\n",
    "index = build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fAqQNsD4pNL"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def mutual_info(word,index=index):\n",
    "  \n",
    "  ranking = {}\n",
    "  docs_word = set(map(lambda x: x[0], index[word]))\n",
    "  n_a = len(docs_word)\n",
    "  \n",
    "  for key in index:\n",
    "    if key != word:\n",
    "      docs_b = set(map(lambda x: x[0], index[key]))\n",
    "      n_b = len(docs_b)\n",
    "      n_ab = len(docs_word & docs_b)\n",
    "      if n_ab == 0: continue\n",
    "      ranking[key] = n_ab/(n_a*n_b)\n",
    "  \n",
    "  return OrderedDict(sorted(ranking.items(), key=lambda x: x[1], reverse=True))\n",
    "  \n",
    "mutual_info(\"governo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Li_6163uKqhs"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def expected_mutual_info(word,index=index):\n",
    "  \n",
    "  ranking = {}\n",
    "  docs_word = set(map(lambda x: x[0], index[word]))\n",
    "  n_a = len(docs_word)\n",
    "  n = len(documents)\n",
    "  \n",
    "  for key in index:\n",
    "    if key != word:\n",
    "      docs_b = set(map(lambda x: x[0], index[key]))\n",
    "      n_b = len(docs_b)\n",
    "      n_ab = len(docs_word & docs_b)\n",
    "      if n_ab == 0: continue\n",
    "      ranking[key] = n_ab * math.log(n*(n_ab/(n_a*n_b)))\n",
    "  \n",
    "  return OrderedDict(sorted(ranking.items(), key=lambda x: x[1], reverse=True))\n",
    "  \n",
    "expected_mutual_info(\"bolsonaro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CsE0eTSMF26"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def chi_square(word,index=index):\n",
    "  \n",
    "  ranking = {}\n",
    "  docs_word = set(map(lambda x: x[0], index[word]))\n",
    "  n_a = len(docs_word)\n",
    "  n = len(documents)\n",
    "  \n",
    "  for key in index:\n",
    "    if key != word:\n",
    "      docs_b = set(map(lambda x: x[0], index[key]))\n",
    "      n_b = len(docs_b)\n",
    "      n_ab = len(docs_word & docs_b)\n",
    "      if n_ab == 0: continue\n",
    "      ranking[key] = (n_ab-(1/n)*n_a*n_b)**2 / (n_a*n_b)\n",
    "  \n",
    "  return OrderedDict(sorted(ranking.items(), key=lambda x: x[1], reverse=True))\n",
    "  \n",
    "chi_square(\"bolsonaro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17401
    },
    "colab_type": "code",
    "id": "vrMHlJn2MPb9",
    "outputId": "13b7dc84-93f4-47bc-bbb0-e4a533b1ba0e"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def dice(word,index=index):\n",
    "  \n",
    "  ranking = {}\n",
    "  docs_word = set(map(lambda x: x[0], index[word]))\n",
    "  n_a = len(docs_word)\n",
    "  \n",
    "  for key in index:\n",
    "    if key != word:\n",
    "      docs_b = set(map(lambda x: x[0], index[key]))\n",
    "      n_b = len(docs_b)\n",
    "      n_ab = len(docs_word & docs_b)\n",
    "      if n_ab == 0: continue\n",
    "      ranking[key] = n_ab/(n_a+n_b)\n",
    "  \n",
    "  return OrderedDict(sorted(ranking.items(), key=lambda x: x[1], reverse=True))\n",
    "  \n",
    "dice(\"governo\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "query_expansion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
