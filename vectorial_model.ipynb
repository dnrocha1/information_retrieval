{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vectorial_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHnz8Cjc0sE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHKiVnrl1MG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/dnrocha1/information_retrieval/master/lab02/data/results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxIXvmRY1NzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pre-process\n",
        "\n",
        "stopwords = stopwords.words('portuguese')\n",
        "documents = data['text'].apply(lambda x: x.lower())\n",
        "\n",
        "regex = RegexpTokenizer(r'\\b[A-zÀ-ú-\\'\\d]{3,}')\n",
        "# tokens = regex.tokenize(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26JkzaIq1TGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_index(documents=documents):\n",
        "  inverted_list = {}\n",
        "  M = len(documents)\n",
        "\n",
        "  n_doc = 0\n",
        "  for document in documents:\n",
        "    token = [w for w in regex.tokenize(document) if w not in stopwords]\n",
        "    counter = list(Counter(token).items())\n",
        "    for elem in counter:\n",
        "      key = elem[0]\n",
        "      freq = elem[1]\n",
        "      if key in inverted_list.keys():\n",
        "        if n_doc not in inverted_list[key][0]:\n",
        "          inverted_list[key].append((n_doc,freq))\n",
        "      else:\n",
        "        inverted_list[key] = [(n_doc,freq)]\n",
        "    n_doc += 1\n",
        "  \n",
        "  for elem in inverted_list:\n",
        "    k = len(inverted_list[elem])\n",
        "    idf = math.log((M+1)/k)\n",
        "    inverted_list[elem].append(idf)\n",
        "  \n",
        "  return inverted_list\n",
        "\n",
        "index = build_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCfTNJ65SmI_",
        "colab_type": "text"
      },
      "source": [
        "TENTAR MUDAR INTERNAMENTE NOS METODOS PRA NÃO TOKENIZAR E SIM BUSCAR A PARTIR DO INDICE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v1iocP61qe9",
        "colab_type": "code",
        "outputId": "0154a22f-59a9-4435-89e3-4609f6e4ff4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocabulary = list(index.keys())\n",
        "\n",
        "def vec_model_bin(query,document,index=index):\n",
        "  q = {}\n",
        "  d = {}\n",
        "  \n",
        "  for word in vocabulary:\n",
        "    q[word] = 0\n",
        "    if word in query.split():\n",
        "      q[word] = 1\n",
        "      \n",
        "  tokens = [w for w in regex.tokenize(document) if w not in stopwords]\n",
        "  for word in vocabulary:\n",
        "    d[word] = 0\n",
        "    if word in list(set(tokens)):\n",
        "      d[word] = 1\n",
        "      \n",
        "  acc = 0\n",
        "  for word in vocabulary:\n",
        "    if q[word] > 0 and d[word] > 0:\n",
        "      acc = acc + q[word]*d[word]\n",
        "      \n",
        "  return acc\n",
        "\n",
        "vec_model_bin(\"juíza federal\",documents[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jQtEV8UPCSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2abac96c-d0f7-45b1-d05d-69964c1a8c2c"
      },
      "source": [
        "def vec_model_tf(query,document,index=index):\n",
        "  q = {}\n",
        "  d = {}\n",
        "  \n",
        "  for word in vocabulary:\n",
        "    q[word] = 0\n",
        "    if word in query.split():\n",
        "      q[word] = 1\n",
        "  \n",
        "  tokens = [w for w in regex.tokenize(document) if w not in stopwords]\n",
        "  counter = Counter(tokens)\n",
        "  \n",
        "  for word in vocabulary:\n",
        "    d[word] = 0\n",
        "    if word in list(counter.keys()):\n",
        "      d[word] = counter[word]\n",
        "      \n",
        "  acc = 0\n",
        "  for word in vocabulary:\n",
        "    if q[word] > 0 and d[word] > 0:\n",
        "      acc = acc + q[word]*d[word]\n",
        "      \n",
        "  return acc\n",
        "\n",
        "vec_model_tf(\"juíza federal\",documents[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duyweJe3bCRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb9ece61-af46-4948-c1d4-297eac3bea7e"
      },
      "source": [
        "def vec_model_tf_idf(query,document,index=index):\n",
        "  q = {}\n",
        "  d = {}\n",
        "  \n",
        "  for word in vocabulary:\n",
        "    q[word] = 0\n",
        "    if word in query.split():\n",
        "      q[word] = 1\n",
        "  \n",
        "  tokens = [w for w in regex.tokenize(document) if w not in stopwords]\n",
        "  counter = Counter(tokens)\n",
        "  \n",
        "  for word in vocabulary:\n",
        "    d[word] = 0\n",
        "    if word in list(counter.keys()):\n",
        "      d[word] = counter[word]\n",
        "      \n",
        "  acc = 0\n",
        "  for word in vocabulary:\n",
        "    idf = index[word][-1]\n",
        "    if q[word] > 0 and d[word] > 0:\n",
        "      acc = acc + q[word]*d[word]*idf\n",
        "      \n",
        "  return acc\n",
        "\n",
        "vec_model_tf_idf(\"juíza federal\",documents[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.957147288513314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}